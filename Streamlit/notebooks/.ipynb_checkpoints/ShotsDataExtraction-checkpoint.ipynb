{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9d3347-22ca-4eab-9af6-474308093ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e0b85f-483f-45fa-b02e-261512331d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import understatapi\n",
    "client = understatapi.UnderstatClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5583e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# Database connection settings (replace with your credentials)\n",
    "db_config = {\n",
    "    'dbname': 'understat_db',\n",
    "    'user': 'ishdeep',\n",
    "    'password': 'ichadhapg',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "}\n",
    "\n",
    "# Create a connection engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\")\n",
    "\n",
    "#with engine.connect() as conn:\n",
    "#    conn.execute('TRUNCATE TABLE understat_shots_tb RESTART IDENTITY CASCADE;')\n",
    "\n",
    "def save_to_postgres(dataframe, table_name):\n",
    "    try:\n",
    "        # Append data to the PostgreSQL table\n",
    "        dataframe.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "        print(f\"Data successfully saved to {table_name} table.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to PostgreSQL: {e}\")\n",
    "\n",
    "\n",
    "def upsert_to_postgres(df, table_name, primary_key, engine):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Begin a transaction\n",
    "            with conn.begin():\n",
    "                # Create a temporary table for the upsert operation\n",
    "                temp_table_name = f\"{table_name}_temp\"\n",
    "                df.to_sql(temp_table_name, con=conn, if_exists='replace', index=False)\n",
    "                \n",
    "                # Construct the merge query using a WITH clause\n",
    "                quoted_columns = [\"X\", \"Y\",\"xG\",\"shotType\",\"lastAction\"]\n",
    "                update_columns = \", \".join([f'\"{col}\" = EXCLUDED.\"{col}\"' if col in quoted_columns else f'{col} = EXCLUDED.{col}' for col in df.columns if col != primary_key])\n",
    "                insert_columns = \", \".join([f'\"{col}\"' if col in quoted_columns else col for col in df.columns])\n",
    "                insert_values = \", \".join([f':{col}' for col in df.columns])\n",
    "\n",
    "                upsert_query = f\"\"\"\n",
    "                INSERT INTO {table_name} ({insert_columns})\n",
    "                SELECT {insert_columns} FROM {temp_table_name}\n",
    "                ON CONFLICT ({primary_key})\n",
    "                DO UPDATE SET {update_columns};\n",
    "                \"\"\"\n",
    "                \n",
    "                # Execute the merge query\n",
    "                conn.execute(upsert_query)\n",
    "                \n",
    "                # Drop the temporary table\n",
    "                conn.execute(f\"DROP TABLE IF EXISTS {temp_table_name};\")\n",
    "                \n",
    "            print(f\"Upsert to table '{table_name}' completed successfully.\")\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error during upsert: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f914112-889b-4bb8-9d0a-0c1926818998",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EPL , Bundesliga , Serie_A , Ligue_1 , La_Liga\n",
    "#league = \"EPL\"\n",
    "#season = \"2024\"\n",
    "\n",
    "league_data = client.league(league=league).get_match_data(season=season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af454b97-6c43-45fa-9963-da982c01e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "\n",
    "for match in league_data:\n",
    "    match_data = {\n",
    "        'id': match['id'],\n",
    "        'home_team': match['h']['title'],\n",
    "        'away_team': match['a']['title'],\n",
    "        'home_goals': match['goals']['h'],\n",
    "        'away_goals': match['goals']['a'],\n",
    "        'home_xG': match['xG']['h'],\n",
    "        'away_xG': match['xG']['a'],\n",
    "        'datetime': match['datetime']\n",
    "        #'forecast': match['forecast']\n",
    "    }\n",
    "    matches.append(match_data)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "matches_df = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010c70-7e04-4e5e-9071-2dbb764c5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shot_data = []\n",
    "\n",
    "import datetime\n",
    "\n",
    "current_timestamp = datetime.datetime.now().timestamp()\n",
    "\n",
    "for index,row in matches_df.iterrows():\n",
    "    match_datetime = pd.to_datetime(row['datetime']).timestamp()\n",
    "    \n",
    "    if match_datetime <= current_timestamp:\n",
    "        #print(row['id'])\n",
    "        try:\n",
    "            shot_data = client.match(match=row['id']).get_shot_data()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        all_shot_data.append(shot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7d1f47-0fa5-43e0-86c0-b1b5a5362047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold individual shot records\n",
    "compiled_shot_data = []\n",
    "\n",
    "# Loop through each match in `all_shot_data`\n",
    "for match in all_shot_data:\n",
    "    # Get home shots and away shots from the match\n",
    "    home_shots = match.get('h', [])\n",
    "    away_shots = match.get('a', [])\n",
    "    \n",
    "    # Add a column to indicate if it's a home or away shot, then extend our list\n",
    "    for shot in home_shots:\n",
    "        shot['h_a'] = 'h'  # Indicate as home shot\n",
    "        compiled_shot_data.append(shot)\n",
    "    \n",
    "    for shot in away_shots:\n",
    "        shot['h_a'] = 'a'  # Indicate as away shot\n",
    "        compiled_shot_data.append(shot)\n",
    "\n",
    "# Convert the list of shot records to a DataFrame\n",
    "compiled_shot_df = pd.DataFrame(compiled_shot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f52b8e-42f5-4c4e-a6d6-2e143084c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_shot_df['league'] = league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674665c4-9ac0-44aa-aaa1-82386a101187",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_shot_df = compiled_shot_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf3ef6b-ba9b-465d-a6a8-4fb7e05115bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_shot_df['id'] = compiled_shot_df['id'].astype(int)\n",
    "compiled_shot_df['minute'] = compiled_shot_df['minute'].astype(int)\n",
    "compiled_shot_df['X'] = pd.to_numeric(compiled_shot_df['X'], errors='coerce')\n",
    "compiled_shot_df['Y'] = pd.to_numeric(compiled_shot_df['Y'], errors='coerce')\n",
    "compiled_shot_df['xG'] = pd.to_numeric(compiled_shot_df['xG'], errors='coerce')\n",
    "compiled_shot_df['player_id'] = compiled_shot_df['player_id'].astype(int)\n",
    "compiled_shot_df['season'] = compiled_shot_df['season'].astype(int)\n",
    "compiled_shot_df['match_id'] = compiled_shot_df['match_id'].astype(int)\n",
    "compiled_shot_df['h_goals'] = compiled_shot_df['h_goals'].astype(int)\n",
    "compiled_shot_df['a_goals'] = compiled_shot_df['a_goals'].astype(int)\n",
    "compiled_shot_df['date'] = pd.to_datetime(compiled_shot_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0b1a5a-eeb3-40b9-b514-c7eb1296103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert to table 'understat_shots_tb' completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_11300\\1035992783.py:51: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  conn.execute(upsert_query)\n"
     ]
    }
   ],
   "source": [
    "#compiled_shot_df.to_csv(f'C:/Users/acer/Documents/GitHub/IndianCitizen/ScorePredict/Data/{league}/2024-25/shot_data.csv')\n",
    "#save_to_postgres(compiled_shot_df, 'understat_shots_tb')\n",
    "upsert_to_postgres(compiled_shot_df, 'understat_shots_tb','id',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5485ea-c63e-42ab-8e8a-f7e89ff93f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
